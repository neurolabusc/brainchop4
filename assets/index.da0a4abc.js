import{t as ae,s as ke,d as j,l as We,a as be,b as ee,c as xe,e as Se,E as ie,m as Re,o as ce,z as ue,f as O,g as qe,w as _e,h as ze,i as Te,j as X,k as Me,n as Ge,p as je,q as ve,r as Pe,u as de,v as Qe,x as oe,y as He,N as Xe}from"./vendor.5623a205.js";const Ue=function(){const e=document.createElement("link").relList;if(e&&e.supports&&e.supports("modulepreload"))return;for(const t of document.querySelectorAll('link[rel="modulepreload"]'))u(t);new MutationObserver(t=>{for(const i of t)if(i.type==="childList")for(const l of i.addedNodes)l.tagName==="LINK"&&l.rel==="modulepreload"&&u(l)}).observe(document,{childList:!0,subtree:!0});function n(t){const i={};return t.integrity&&(i.integrity=t.integrity),t.referrerpolicy&&(i.referrerPolicy=t.referrerpolicy),t.crossorigin==="use-credentials"?i.credentials="include":t.crossorigin==="anonymous"?i.credentials="omit":i.credentials="same-origin",i}function u(t){if(t.ep)return;t.ep=!0;const i=n(t);fetch(t.href,i)}};Ue();const Ze={batchSize:1,numOfChan:1,isColorEnable:!0,isAutoColors:!0,bgLabelValue:0,drawBoundingVolume:!1,isGPU:!0,isBrainCropMaskBased:!0,showPhase1Output:!1,isPostProcessEnable:!0,isContoursViewEnable:!1,browserArrayBufferMaxZDim:30,telemetryFlag:!1,chartXaxisStepPercent:10,uiSampleName:"BC_UI_Sample",atlasSelectedColorTable:"Fire",deleteTextureThreshold:-1},D=[{id:1,type:"Segmentation",path:"/models/model5_gw_ae/model.json",modelName:"\u26A1 Tissue GWM (light)",colormapPath:"./models/model5_gw_ae/colormap3.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:18,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:null,inferenceDelay:100,description:"Gray and white matter segmentation model. Operates on full T1 image in a single pass, but uses only 5 filters per layer. Can work on integrated graphics cards but is barely large enough to provide good accuracy. Still more accurate than the subvolume model."},{id:2,type:"Segmentation",path:"/models/model20chan3cls/model.json",modelName:"\u{1F52A} Tissue GWM (High Acc)",colormapPath:"./models/model20chan3cls/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:.2,enableQuantileNorm:!0,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Gray and white matter segmentation model. Operates on full T1 image in a single pass but needs a dedicated graphics card to operate. Provides the best accuracy with hard cropping for better speed"},{id:3,type:"Segmentation",path:"/models/model20chan3cls/model.json",modelName:"\u{1F52A} Tissue GWM (High Acc, Low Mem)",colormapPath:"./models/model20chan3cls/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:.2,enableQuantileNorm:!0,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Gray and white matter segmentation model. Operates on full T1 image in a single pass but needs a dedicated graphics card to operate. Provides high accuracy and fit low memory available but slower"},{id:4,type:"Atlas",path:"/models/model30chan18cls/model.json",modelName:"\u{1FA93} Subcortical + GWM (High Mem, Fast)",colormapPath:"./models/model30chan18cls/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:.2,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Parcellation of the brain into 17 regions: gray and white matter plus subcortical areas. This is a robust model able to handle range of data quality, including varying saturation, and even clinical scans. It may work on infant brains, but your mileage may vary."},{id:5,type:"Atlas",path:"/models/model30chan18cls/model.json",modelName:"\u{1FA93} Subcortical + GWM (Low Mem, Slow)",colormapPath:"./models/model30chan18cls/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:.2,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Parcellation of the brain into 17 regions: gray and white matter plus subcortical areas. This is a robust model able to handle range of data quality, including varying saturation, and even clinical scans. It may work on infant brains, but your mileage may vary."},{id:6,type:"Atlas",path:"/models/model18cls/model.json",modelName:"\u{1FA93} Subcortical + GWM (Low Mem, Faster)",colormapPath:"./models/model18cls/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:.2,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Parcellation of the brain into 17 regions: gray and white matter plus subcortical areas. This is a robust model able to handle range of data quality, including varying saturation, and even clinical scans. It may work on infant brains, but your mileage may vary."},{id:7,type:"Atlas",path:"/models/model30chan18cls/model.json",modelName:"\u{1F52A}\u{1FA93} Subcortical + GWM (Failsafe, Less Acc)",colormapPath:"./models/model30chan18cls/colormap.json",preModelId:1,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Parcellation of the brain into 17 regions: gray and white matter plus subcortical areas. This is not a robust model, it may work on low data quality, including varying saturation, and even clinical scans. It may work also on infant brains, but your mileage may vary."},{id:8,type:"Atlas",path:"/models/model30chan50cls/model.json",modelName:"\u{1F52A} Aparc+Aseg 50 (High Mem, Fast)",colormapPath:"./models/model30chan50cls/colormap.json",preModelId:1,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!0,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"This is a 50-class model, that segments the brain into the Aparc+Aseg Freesurfer Atlas but one where cortical homologues are merged into a single class."},{id:9,type:"Atlas",path:"/models/model30chan50cls/model.json",modelName:"\u{1F52A} Aparc+Aseg 50 (Low Mem, Slow)",colormapPath:"./models/model30chan50cls/colormap.json",preModelId:1,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!0,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"This is a 50-class model, that segments the brain into the Aparc+Aseg Freesurfer Atlas but one where cortical homologues are merged into a single class. The model use sequential convolution for inference to overcome browser memory limitations but leads to longer computation time."},{id:10,type:"Brain_Extraction",path:"/models/model5_gw_ae/model.json",modelName:"\u26A1 Extract the Brain (FAST)",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:18,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:null,inferenceDelay:100,description:"Extract the brain fast model operates on full T1 image in a single pass, but uses only 5 filters per layer. Can work on integrated graphics cards but is barely large enough to provide good accuracy. Still more accurate than the failsafe version."},{id:11,type:"Brain_Extraction",path:"/models/model11_gw_ae/model.json",modelName:"\u{1F52A} Extract the Brain (High Acc, Slow)",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"Extract the brain high accuracy model operates on full T1 image in a single pass, but uses only 11 filters per layer. Can work on dedicated graphics cards. Still more accurate than the fast version."},{id:12,type:"Brain_Masking",path:"/models/model5_gw_ae/model.json",modelName:"\u26A1 Brain Mask (FAST)",colormapPath:"./models/model5_gw_ae/colormap.json",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:17,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:null,inferenceDelay:100,description:"This fast masking model operates on full T1 image in a single pass, but uses only 5 filters per layer. Can work on integrated graphics cards but is barely large enough to provide good accuracy. Still more accurate than failsafe version."},{id:13,type:"Brain_Masking",path:"/models/model11_gw_ae/model.json",modelName:"\u{1F52A} Brain Mask (High Acc, Low Mem)",preModelId:null,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:0,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!0,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"This masking model operates on full T1 image in a single pass, but uses 11 filters per layer. Can work on dedicated graphics cards. Still more accurate than fast version."},{id:14,type:"Atlas",path:"/models/model21_104class/model.json",modelName:"\u{1F52A} Aparc+Aseg 104 (High Mem, Fast)",colormapPath:"./models/model21_104class/colormap.json",preModelId:0,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!1,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"FreeSurfer aparc+aseg atlas 104 parcellate brain areas into 104 regions. It contains a combination of the Desikan-Killiany atlas for cortical area and also segmentation of subcortical regions."},{id:15,type:"Atlas",path:"/models/model21_104class/model.json",modelName:"\u{1F52A} Aparc+Aseg 104 (Low Mem, Slow)",colormapPath:"./models/model21_104class/colormap.json",preModelId:0,preModelPostProcess:!1,isBatchOverlapEnable:!1,numOverlapBatches:200,enableTranspose:!0,enableCrop:!0,cropPadding:0,autoThreshold:0,enableQuantileNorm:!1,filterOutWithPreMask:!1,enableSeqConv:!0,textureSize:0,warning:"This model may need dedicated graphics card.  For more info please check with Browser Resources <i class='fa fa-cogs'></i>.",inferenceDelay:100,description:"FreeSurfer aparc+aseg atlas 104 parcellate brain areas into 104 regions. It contains a combination of the Desikan-Killiany atlas for cortical area and also segmentation of subcortical regions. The model use sequential convolution for inference to overcome browser memory limitations but leads to longer computation time. "}];class Ke{idx(e,n,u,t){return u*t[0]*t[1]+n*t[0]+e}check_previous_slice(e,n,u,t,i,l,a,f,d,o){let s=0;if(!i)return 0;const h=e[this.idx(u,t,i,l)];if(a>=6){const p=this.idx(u,t,i-1,l);h===e[p]&&(d[s++]=n[p])}if(a>=18){if(u){const p=this.idx(u-1,t,i-1,l);h===e[p]&&(d[s++]=n[p])}if(t){const p=this.idx(u,t-1,i-1,l);h===e[p]&&(d[s++]=n[p])}if(u<l[0]-1){const p=this.idx(u+1,t,i-1,l);h===e[p]&&(d[s++]=n[p])}if(t<l[1]-1){const p=this.idx(u,t+1,i-1,l);h===e[p]&&(d[s++]=n[p])}}if(a===26){if(u&&t){const p=this.idx(u-1,t-1,i-1,l);h===e[p]&&(d[s++]=n[p])}if(u<l[0]-1&&t){const p=this.idx(u+1,t-1,i-1,l);h===e[p]&&(d[s++]=n[p])}if(u&&t<l[1]-1){const p=this.idx(u-1,t+1,i-1,l);h===e[p]&&(d[s++]=n[p])}if(u<l[0]-1&&t<l[1]-1){const p=this.idx(u+1,t+1,i-1,l);h===e[p]&&(d[s++]=n[p])}}return s?(this.fill_tratab(f,d,s,o),d[0]):0}do_initial_labelling(e,n,u){const t=new Uint32Array(32),i=new Uint32Array(32);let l=1;const a=8192;let f=a,d=new Uint32Array(f).fill(0);const o=new Uint32Array(n[0]*n[1]*n[2]).fill(0),s=new Uint32Array(27);for(let h=0;h<n[2];h++)for(let p=0;p<n[1];p++)for(let c=0;c<n[0];c++){let m=0;const y=e[this.idx(c,p,h,n)];if(y!==0){if(s[0]=this.check_previous_slice(e,o,c,p,h,n,u,d,t,i),s[0]&&(m+=1),u>=6){if(c){const g=this.idx(c-1,p,h,n);y===e[g]&&(s[m++]=o[g])}if(p){const g=this.idx(c,p-1,h,n);y===e[g]&&(s[m++]=o[g])}}if(u>=18){if(p&&c){const g=this.idx(c-1,p-1,h,n);y===e[g]&&(s[m++]=o[g])}if(p&&c<n[0]-1){const g=this.idx(c+1,p-1,h,n);y===e[g]&&(s[m++]=o[g])}}if(m)o[this.idx(c,p,h,n)]=s[0],this.fill_tratab(d,s,m,i);else{if(o[this.idx(c,p,h,n)]=l,l>=f){f+=a;const g=new Uint32Array(f);g.set(d),d=g}d[l-1]=l,l++}}}for(let h=0;h<l-1;h++){let p=h;for(;d[p]!==p+1;)p=d[p]-1;d[h]=p+1}return[l-1,d,o]}fill_tratab(e,n,u,t){let l=2147483647;for(let a=0;a<u;a++){let f=n[a];for(;e[f-1]!==f;)f=e[f-1];t[a]=f,l=Math.min(l,f)}for(let a=0;a<u;a++)e[t[a]-1]=l}translate_labels(e,n,u,t){const i=n[0]*n[1]*n[2];let l=0;const a=new Uint32Array(i).fill(0);for(let o=0;o<t;o++)l=Math.max(l,u[o]);const f=new Uint32Array(l).fill(0);let d=0;for(let o=0;o<i;o++)e[o]&&(f[u[e[o]-1]-1]||(d+=1,f[u[e[o]-1]-1]=d),a[o]=f[u[e[o]-1]-1]);return[d,a]}largest_original_cluster_labels(e,n,u){const t=e.length,i=new Uint32Array(n+1).fill(0),l=new Uint32Array(n+1).fill(0);for(let d=0;d<t;d++){const o=e[d],s=u[d];i[s]=o,l[s]++}let a=0;for(let d=0;d<n+1;d++){const o=i[d];a=Math.max(a,o);for(let s=0;s<n+1;s++)s!==d&&o===i[s]&&(l[d]<l[s]||l[d]===l[s]&&d<s)&&(i[d]=0)}const f=new Uint32Array(t).fill(0);for(let d=0;d<t;d++)f[d]=i[u[d]];return[a,f]}bwlabel(e,n,u=26,t=!1,i=!1){const l=Date.now(),a=n[0]*n[1]*n[2],f=new Uint32Array(a).fill(0);if(![6,18,26].includes(u))return console.log("bwlabel: conn must be 6, 18 or 26."),[0,f];if(n[0]<2||n[1]<2||n[2]<1)return console.log("bwlabel: img must be 2 or 3-dimensional"),[0,f];if(t)for(let c=0;c<a;c++)e[c]!==0&&(f[c]=1);else f.set(e);let[d,o,s]=this.do_initial_labelling(f,n,u);o===void 0&&(o=new Uint32Array(0));const[h,p]=this.translate_labels(s,n,o,d);if(console.log(u+" neighbor clustering into "+h+" regions in "+(Date.now()-l)+"ms"),i){const[c,m]=this.largest_original_cluster_labels(f,h,p);return[c,m]}return[h,p]}}async function Ce(r,e=[1,1],n=[1,1],u=[1,1]){if(r.rank!==3)throw new Error("Tensor must be 3D");return r.pad([e,n,u])}async function Le(r,e){const n=r.max(),u=n.mul(e),t=await u.data();return n.dispose(),u.dispose(),ee(()=>r.clone().greater(t[0]))}async function pe(r){const e=0;return r.step(e)}async function Je(r,e=.01,n=.99){const u=r.flatten(),t=await u.array();t.sort((p,c)=>p-c);const i=xe(t),l=i.shape[0],a=Math.floor(l*e),f=Math.ceil(l*n)-1,d=i.slice(a,1),o=i.slice(f,1),s=(await d.array())[0],h=(await o.array())[0];return u.dispose(),i.dispose(),d.dispose(),o.dispose(),{qmin:s,qmax:h}}async function $e(r,e,n,u,t,i,l){const a=r.shape[4],f=e.shape[4];let d=null;for(let o=0;o<f;o++){const s=Math.ceil(a/l),h=n.slice([o],[1]);let p=null;for(let m=0;m<s;m++){const y=m*l,g=Math.min((m+1)*l,a);if(y<a){const x=ee(()=>{const b=r.slice([0,0,0,0,y],[-1,-1,-1,-1,g-y]),C=e.slice([0,0,0,y,o],[-1,-1,-1,g-y,1]);return Se(b,C,u,t,"NDHWC",i)});if(p===null)p=x;else{const b=p.add(x);p.dispose(),x.dispose(),p=b}}}const c=p.add(h);if(p.dispose(),h.dispose(),d==null)d=c;else{const m=await Ge([d,c],4);c.dispose(),d.dispose(),d=m}}return d}async function Oe(r,e,n,u){const t=[];for(let d=0;d<r.length;d++)t[d]=Array.from(r[d].dataSync());const i=new Array(t[0].length*t.length);let l=0;for(let d=0;d<t.length;d++)for(let o=0;o<t[d].length;o++)i[l++]=t[d][o];console.log("Done with allOutputSlices3DCC1DimArray ");const a=await pe(xe(i)),f=Array.from(a.dataSync());u(f,e,n)}async function fe(r,e=0){let n=[];e===0?n=await r.max(2).max(1).arraySync():e===1?n=await r.max(2).max(0).arraySync():n=await r.max(1).max(0).arraySync();let u=n.length,t=0;for(let i=0;i<n.length;i++)if(n[i]>0){u=i;break}for(let i=n.length-1;i>=0;i--)if(n[i]>0){t=i;break}return[u,t]}async function Ie(r){const[e,n]=await fe(r,0),[u,t]=await fe(r,1),[i,l]=await fe(r,2);return console.log("row min and max  :",e,n),console.log("col min and max  :",u,t),console.log("depth min and max  :",i,l),[e,n,u,t,i,l]}async function Ye(r,e,n,u,t,i,l,a,f=!0){r[0].dtype!=="int32"&&l("",-1,"generateBrainMask assumes int32"),t.preModelPostProcess&&l("",-1,"generateBrainMask assumes BWLabeler instead of preModelPostProcess");const d=r.length,o=r[0].size,s=d*o,h=new Int32Array(s);let p=0;for(let c=0;c<d;c++)h.set(r[c].dataSync(),p),p+=o;for(let c=0;c<s;c++)h[c]=h[c]!==0?1:0;return(f||i.showPhase1Output)&&(a(h,i,t),l("Segmentation finished",0)),ae(h,[e,n,u])}async function Ae(r,e,n,u,t,i,l,a,f,d){if(f.isPostProcessEnable){const s=new Ke,h=new Uint32Array(e),p=26,c=!0,m=!0,[y,g]=s.bwlabel(r,h,p,c,m);for(let x=0;x<r.length;x++)r[x]*=g[x]}const o=new Uint8Array(r);switch(a.type){case"Brain_Masking":{const s=new Uint8Array(o.length);for(let h=0;h<o.length;h++)s[h]=o[h]!==0?1:0;return s}case"Brain_Extraction":{const s=new Uint8Array(o.length);for(let h=0;h<o.length;h++){const p=o[h]!==0?1:0;s[h]=d[h]*p}return s}}return r}async function De(r,e,n){const u=e.dims[1],t=e.dims[2];let i;if(e.datatypeCode===2)i=new Uint8Array(n);else if(e.datatypeCode===4)i=new Int16Array(n);else if(e.datatypeCode===8)i=new Int32Array(n);else if(e.datatypeCode===16)i=new Float32Array(n);else if(e.datatypeCode===64)i=new Float64Array(n);else if(e.datatypeCode===256)i=new Int8Array(n);else if(e.datatypeCode===512)i=new Uint16Array(n);else if(e.datatypeCode===768)i=new Uint32Array(n);else return;const l=[];let a=0;for(let d=0;d<r;d++){const o=new Array(t*u);let s=0;for(let h=0;h<t;h++)for(let p=0;p<u;p++){const c=i[a++];o[s++]=c&255}l.push(ae(o,[t,u]))}const f=ke(l);return j(l),f}async function he(r){return r.layers.length}async function me(r){let e=0;for(let n=0;n<r.layers.length;n++)e+=r.layers[n].countParams();return e}async function re(r){for(let e=0;e<r.layers.length;e++)if(r.layersByDepth[e][0].dataFormat)return r.layersByDepth[e][0].dataFormat==="channelsLast"}async function Ee(r){return await We(r)}async function ge(r){const e=r.max(),n=r.min();return await r.sub(n).div(e.sub(n))}function eo(r,e,n){const u=1,t=0,i=1,l=r.shape[4],a=Math.ceil(l/n);let f=null;for(let d=0;d<a;d++){const o=d*n,h=Math.min((d+1)*n,l)-o,p=ee(()=>r.slice([0,0,0,0,o],[-1,-1,-1,-1,h])),c=ee(()=>e.slice([0,0,0,o,0],[-1,-1,-1,h,-1])),m=Se(p,c,u,t,"NDHWC",i);p.dispose(),c.dispose();const y=je(m);if(m.dispose(),f===null)f=y;else{const g=f.add(y);f.dispose(),f!==y&&y.dispose(),f=g}ee(()=>{Te(ue([1,1]),ue([1,1]))})}return f}async function ye(r,e=.05,n=.95){const{qmin:u,qmax:t}=await Je(r,e,n),i=be(u),l=be(t),a=r.sub(i).div(l.sub(i));return i.dispose(),l.dispose(),a}async function se(r,e=1,n=1,u=1){if(r.rank!==3)throw new Error("Tensor must be 3D");const[t,i,l]=r.shape;return r.slice([e,n,u],[t-2*e,i-2*n,l-2*u])}async function te(r,e,n,u,t,i){const l=t[0],a=t[1],f=t[2],d=l+i[0]-1,o=a+i[1]-1,s=f+i[2]-1,h=n-d-1>0?n-d-1:0,p=u-o-1>0?u-o-1:0,c=e-s-1>0?e-s-1:0;return r.pad([[l,h],[a,p],[f,c]])}class oo{constructor(e,n,u,t,i=!0){this.model=e,this.outChannels=e.outputLayers[0].kernel.shape[4],this.chunkSize=n,this.isChannelLast=u,this.callbackUI=t,this.isWebWorker=i}async apply(e,n=0){const u=ie.get("WEBGL_DELETE_TEXTURE_THRESHOLD");ie.set("WEBGL_DELETE_TEXTURE_THRESHOLD",n);const t=this,i=performance.now(),l=t.model.layers[t.model.layers.length-1],a=l.getWeights()[0],f=l.getWeights()[1],d=t.isChannelLast?e.shape.slice(1,-1):e.shape.slice(2);let o=Re(ce(d),-1e4),s=ue(d),h=0;for(console.log(" channel loop");;){O().startScope();const p=await ee(()=>{const m=a.slice([0,0,0,0,h],[-1,-1,-1,-1,1]),y=f.slice([h],[1]),g=eo(e,m,Math.min(t.chunkSize,t.outChannels)).add(y),x=qe(g,o),b=_e(x,g,o),C=_e(x,ze(s.shape,h),s);return j([o,s,m,y,g,x]),ee(()=>Te(ce([1,1]),ce([1,1]))),[C,b]});console.log("======================="),t.callbackUI(`Iteration ${h}`,h/t.outChannels),t.isWebWorker||await new Promise(m=>setTimeout(m,17));const c=await X();if(console.log(`Number of Tensors: ${c.numTensors}`),console.log(`Number of Data Buffers: ${c.numDataBuffers}`),console.log(`Megabytes In Use: ${(c.numBytes/1048576).toFixed(3)} MB`),c.unreliable&&console.log(`Unreliable: ${c.unreliable}`),typeof s!="undefined"&&s.dispose(),typeof o!="undefined"&&o.dispose(),s=Me(p[0]),o=Me(p[1]),O().endScope(),h===t.outChannels-1){j(o);const y=performance.now()-i;return console.log(`Execution time for output layer: ${y} milliseconds`),ie.set("WEBGL_DELETE_TEXTURE_THRESHOLD",u),s}else{h++;const m=s.shape,y=s.dataSync(),g=s.shape,x=o.dataSync();s.dispose(),o.dispose(),s=ae(y,m),o=ae(x,g)}}}}async function Be(r,e,n,u,t,i,l,a,f,d,o,s){console.log(" ---- Start FullVolume Inference with Sequential Conv Layer for phase-II ---- "),e.enableQuantileNorm?(console.log("preModel Quantile normalization enabled"),u=await ye(u)):(console.log("preModel Min Max normalization enabled"),u=await ge(u));let p;if(a==null){const I=e.autoThreshold;I>0&&I<=1?p=await Le(u,I):(console.log("No valid crop threshold value"),p=await u.greater([0]).asType("bool"))}else p=await a.greater([0]).asType("bool");console.log(" mask_3d shape :  ",p.shape);const[c,m,y,g,x,b]=await Ie(p);p.dispose();const C=[c,y,x],R=[m-c+1,g-y+1,b-x+1],U=await u.slice([c,y,x],[m-c+1,g-y+1,b-x+1]);u.dispose();const _=e.cropPadding;let v=await Ce(U,[_,_],[_,_],[_,_]);if(console.log(" cropped slices_3d with padding shape:  ",v.shape),U.dispose(),r.drawBoundingVolume){let I=await se(v,_,_,_);return console.log(" outLabelVolume without padding shape :  ",I.shape),I=await te(I,t,i,l,C,R),console.log(" outLabelVolume final shape after resizing :  ",I.shape),Oe(de(I),r,e,d),I.dispose(),0}o.Brainchop_Ver="FullVolume";const w=await n;try{let I=performance.now();const Q=performance.now();let L=0;const M=e.enableTranspose,J=e.inferenceDelay;console.log("Inference delay :",J),M?(v=await v.transpose(),console.log("Input transposed for pre-model")):console.log("Transpose not enabled for pre-model");let T=1;const Z=w.layers.length;console.log("res.layers.length ",Z);const S=re(w),H=r.batchSize,k=r.numOfChan;let $;S?(w.layers[0].batchInputShape[1]=v.shape[0],w.layers[0].batchInputShape[2]=v.shape[1],w.layers[0].batchInputShape[3]=v.shape[2],$=[H,w.layers[0].batchInputShape[1],w.layers[0].batchInputShape[2],w.layers[0].batchInputShape[3],k]):(w.layers[0].batchInputShape[2]=v.shape[0],w.layers[0].batchInputShape[3]=v.shape[1],w.layers[0].batchInputShape[4]=v.shape[2],$=[H,k,w.layers[0].batchInputShape[2],w.layers[0].batchInputShape[3],w.layers[0].batchInputShape[4]]),console.log(" Model batch input shape : ",w.layers[0].batchInputShape),o.Input_Shape=JSON.stringify(w.layers[0].batchInputShape),o.Output_Shape=JSON.stringify(w.output.shape),o.Channel_Last=S,o.Model_Param=await me(w),o.Model_Layers=await he(w),o.Model=e.modelName,o.Seq_Conv=e.enableSeqConv,o.Extra_Info=null;const K=w.layers[w.layers.length-1];console.log("Output Layer : ",K);const B=S?K.outputShape[K.outputShape.length-1]:K.outputShape[1];console.log("Num of output channels : ",B);const E=[];E[0]=await v.reshape($);const q=window.setInterval(async function(){try{w.layers[T].activation.getClassName()!=="linear"?E[T]=await w.layers[T].apply(E[T-1],r.deleteTextureThreshold):E[T]=await $e(E[T-1],w.layers[T].getWeights()[0],w.layers[T].getWeights()[1],w.layers[T].strides,w.layers[T].padding,w.layers[T].dilationRate,3),j(E[T-1])}catch(F){const N="Your graphics card (e.g. Intel) may not be compatible with WebGL. "+F.message;return f(N,-1,N),window.clearInterval(q),O().endScope(),O().disposeVariables(),o.Inference_t=1/0,o.Postprocess_t=1/0,o.Status="Fail",o.Error_Type=F.message,o.Extra_Err_Info="Failed while model layer "+T+" apply",f("",-1,"",o),0}if(console.log("layer output Tensor shape : ",E[T].shape),console.log("layer count params ",w.layers[T].countParams()),w.layers[T].dispose(),E[T-1].dispose(),f("Layer "+T.toString(),(T+1)/Z),X().unreliable){const F="unreliable reasons :"+X().reasons;f(F,NaN,F)}if(T===Z-2){window.clearInterval(q);const N=await(await new oo(w,10,S,f,!1)).apply(E[T],r.deleteTextureThreshold);if(f("seqConvLayer Done"),j(E[T]),console.log(" Output tensor",N),console.log(" Output tensor shape : ",N.shape),N.shape.length!==3){const A="Output tensor shape should be 3 dims but it is "+N.shape.length;f(A,-1,A)}const z=((performance.now()-I)/1e3).toFixed(4);console.log(" find array max ");const W=await N.max().dataSync()[0];L<W&&(L=W);const V=L+1;if(console.log("Predicted num of segmentation classes",V),o.Actual_Labels=V,o.Expect_Labels=B,o.NumLabels_Match=V===B,V!==B){const A="expected "+B+" labels, but the predicted are "+V;f(A,-1,A)}let P=N.reshape([v.shape[0],v.shape[1],v.shape[2]]);j(N),M&&(console.log("outLabelVolume transposed"),P=P.transpose()),P=await se(P,_,_,_),console.log(" outLabelVolume without padding shape :  ",P.shape),P=await te(P,t,i,l,C,R),console.log(" outLabelVolume final shape after resizing :  ",P.shape);const le=e.filterOutWithPreMask;if(a!=null&&r.isBrainCropMaskBased&&le){const A=await pe(a);P=await P.mul(A)}I=performance.now(),console.log("Generating correct output");let ne;try{const A=await new Uint32Array(P.dataSync()),Y=P.shape,Ve=P.dtype;ne=await Ae(A,Y,Ve,t,V,i,l,e,r,s),console.log(" Phase-2 num of tensors after generateOutputSlicesV2: ",X().numTensors),j(P),O().endScope(),O().disposeVariables()}catch(A){O().endScope(),O().disposeVariables(),console.log("Error while generating output: ",A);const Y="Failed while generating output due to limited browser memory available";return f(Y,-1,Y),o.Inference_t=z,o.Postprocess_t=1/0,o.Status="Fail",o.Error_Type=A.message,o.Extra_Err_Info="Failed while generating output",f("",-1,"",o),0}const G=((performance.now()-I)/1e3).toFixed(4);return console.log("Processing the whole brain volume in tfjs for multi-class output mask took : ",((performance.now()-Q)/1e3).toFixed(4)+"  Seconds"),o.Inference_t=z,o.Postprocess_t=G,o.Status="OK",f("",-1,"",o),f("Segmentation finished",0),d(ne,r,e),0}else T++},J)}catch(I){if(f(I.message,-1,I.message),console.log('If webgl context is lost, try to restore webgl context by visit the link <a href="https://support.biodigital.com/hc/en-us/articles/218322977-How-to-turn-on-WebGL-in-my-browser">here</a>'),X().unreliable){const Q="unreliable reasons :"+X().reasons;f(Q,NaN,Q)}}}async function Ne(r,e,n,u,t,i,l,a,f,d,o,s){let h=[];console.log(" ---- Start FullVolume inference phase-II ---- "),l.enableQuantileNorm?(console.log("preModel Quantile normalization enabled"),e=await ye(e)):(console.log("preModel Min Max normalization enabled"),e=await ge(e));let c;if(i==null){const M=l.autoThreshold;M>0&&M<=1?c=await Le(e,M):(console.log("No valid crop threshold value"),c=await e.greater([0]).asType("bool"))}else c=i.greater([0]).asType("bool");console.log(" mask_3d shape :  ",c.shape);const[m,y,g,x,b,C]=await Ie(c);c.dispose();const R=[m,g,b];console.log("refVoxel :",R);const U=[y-m+1,x-g+1,C-b+1];console.log("boundVolSizeArr :",U);const _=e.slice([m,g,b],[y-m+1,x-g+1,C-b+1]);e.dispose();const v=l.cropPadding;let w=await Ce(_,[v,v],[v,v],[v,v]);if(console.log(" cropped slices_3d with padding shape:  ",w.shape),_.dispose(),f.drawBoundingVolume){let M=await se(w,v,v,v);return console.log(" outLabelVolume without padding shape :  ",M.shape),M=await te(M,n,u,t,R,U),console.log(" outLabelVolume final shape after resizing :  ",M.shape),Oe(de(M),f,l,d),M.dispose(),0}a.Brainchop_Ver="FullVolume";let I=performance.now(),Q=[];const L=await r;try{I=performance.now();const M=performance.now();let J=0;const T=l.enableTranspose,Z=l.inferenceDelay;console.log("Inference delay :",Z),T?(w=w.transpose(),console.log("Input transposed for pre-model")):console.log("Transpose not enabled for pre-model");let S=1;const H=L.layers.length;console.log("res.layers.length ",H);const k=await re(L),$=f.batchSize,K=f.numOfChan;k?(L.layers[0].batchInputShape[1]=w.shape[0],L.layers[0].batchInputShape[2]=w.shape[1],L.layers[0].batchInputShape[3]=w.shape[2],Q=[$,L.layers[0].batchInputShape[1],L.layers[0].batchInputShape[2],L.layers[0].batchInputShape[3],K]):(L.layers[0].batchInputShape[2]=w.shape[0],L.layers[0].batchInputShape[3]=w.shape[1],L.layers[0].batchInputShape[4]=w.shape[2],Q=[$,K,L.layers[0].batchInputShape[2],L.layers[0].batchInputShape[3],L.layers[0].batchInputShape[4]]),console.log(" Model batch input shape : ",L.layers[0].batchInputShape),a.Input_Shape=JSON.stringify(L.layers[0].batchInputShape),a.Output_Shape=JSON.stringify(L.output.shape),a.Channel_Last=k,a.Model_Param=await me(L),a.Model_Layers=await he(L),a.Model=l.modelName,a.Extra_Info=null;const B=[];B[0]=w.reshape(Q);const E=window.setInterval(async function(){try{B[S]=L.layers[S].apply(B[S-1],f.deleteTextureThreshold)}catch(q){return o(q.message,-1,q.message),window.clearInterval(E),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=q.message,a.Extra_Err_Info="Failed while model layer "+S+" apply",o("",-1,"",a),0}if(o("Layer "+S.toString(),(S+1)/H),console.log("layer output Tensor shape : ",B[S].shape),console.log("layer count params ",L.layers[S].countParams()),L.layers[S].dispose(),B[S-1].dispose(),X().unreliable){const q="unreliable reasons :"+X().reasons;o(q,NaN,q)}if(S===H-1){window.clearInterval(E);const q=k?-1:1;console.log(" find argmax "),console.log("last Tensor shape : ",B[S].shape);const F=k?B[S].shape[4]:B[S].shape[1];let N;try{const G=performance.now();console.log(" Try tf.argMax for fullVolume .."),N=Pe(B[S],q),console.log("tf.argMax for fullVolume takes : ",((performance.now()-G)/1e3).toFixed(4))}catch(G){if(q===-1)try{const A=performance.now();console.log(" tf.argMax failed .. try argMaxLarge .."),window.alert("tensor2LightBuffer() is not dead code?"),window.alert("argMaxLarge() is not dead code?"),console.log("argMaxLarge for fullVolume takes : ",((performance.now()-A)/1e3).toFixed(4))}catch(A){const Y="argMax buffer couldn't be created due to limited memory resources.";return o(Y,-1,Y),window.clearInterval(E),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=A.message,a.Extra_Err_Info="prediction_argmax from argMaxLarge failed",o("",-1,"",a),0}else{const A="argMax buffer couldn't be created due to limited memory resources.";return o(A,-1,A),N.dispose(),window.clearInterval(E),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=G.message,a.Extra_Err_Info="prediction_argmax from argMaxLarge not support yet channel first",o("",-1,"",a),0}}console.log(" prediction_argmax shape : ",N.shape);const z=((performance.now()-I)/1e3).toFixed(4);j(B[S]);const W=await N.max().dataSync()[0];J<W&&(J=W);const V=J+1;if(console.log("numSegClasses",V),a.Actual_Labels=V,a.Expect_Labels=F,a.NumLabels_Match=V===F,V!==F){const G="expected "+F+" labels, but the predicted are "+V;o(G,-1,G)}let P=N.reshape([w.shape[0],w.shape[1],w.shape[2]]);j(N),T&&(console.log("outLabelVolume transposed"),P=P.transpose()),P=await se(P,v,v,v),console.log(" outLabelVolume without padding shape :  ",P.shape),P=await te(P,n,u,t,R,U),console.log(" outLabelVolume final shape after resizing :  ",P.shape);const le=l.filterOutWithPreMask;if(i!=null&&f.isBrainCropMaskBased&&le){const G=pe(i);P=P.mul(G)}I=performance.now(),console.log("Generating correct output");try{const G=new Uint32Array(P.dataSync()),A=P.shape,Y=P.dtype;j(P),O().endScope(),O().disposeVariables(),h=await Ae(G,A,Y,n,V,u,t,l,f,s),console.log(" Phase-2 num of tensors after generateOutputSlicesV2: ",X().numTensors)}catch(G){O().endScope(),O().disposeVariables();const A="Failed while generating output due to limited browser memory available";return o(A,-1,A),a.Inference_t=z,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=G.message,a.Extra_Err_Info="Failed while generating output",o("",-1,"",a),0}const ne=((performance.now()-I)/1e3).toFixed(4);return O().disposeVariables(),console.log("Processing the whole brain volume in tfjs for multi-class output mask took : ",((performance.now()-M)/1e3).toFixed(4)+"  Seconds"),a.Inference_t=z,a.Postprocess_t=ne,a.Status="OK",o("",-1,"",a),clearInterval(E),o("Segmentation finished",0),d(h,f,l),0}S++},Z)}catch(M){o(M.message,-1,M.message),console.log('If webgl context is lost, try to restore webgl context by visit the link <a href="https://support.biodigital.com/hc/en-us/articles/218322977-How-to-turn-on-WebGL-in-my-browser">here</a>')}}async function no(r,e,n,u,t,i,l,a,f,d,o,s){if(a.No_SubVolumes=1,l.preModelId){const h=await Ee(f.rootURL+D[l.preModelId-1].path),p=D[l.preModelId-1].enableTranspose,c=D[l.preModelId-1].enableQuantileNorm;let m=null;c?(console.log("preModel Quantile normalization enabled"),m=await ye(e)):(console.log("preModel Min Max normalization enabled"),m=await ge(e)),p?(m=await m.transpose(),console.log("Input transposed for pre-model")):console.log("Transpose not enabled for pre-model"),a.Brainchop_Ver="PreModel_FV";const y=await h;try{const g=performance.now(),x=y,b=x.layers[0].batchInputShape;if(console.log(" Pre-Model batch input shape : ",b),b.length!==5){const S="The pre-model input shape must be 5D ";return o(S,-1,S),0}const C=re(x),R=f.batchSize,U=f.numOfChan;let _,v,w,I;if(C){if(console.log("Pre-Model Channel Last"),isNaN(b[4])||b[4]!==1){const S="The number of channels for pre-model input shape must be 1";return o(S,-1,S),0}_=b[1],v=b[2],w=b[3],I=[R,_,v,w,U]}else{if(console.log("Pre-Model Channel First"),isNaN(b[1])||b[1]!==1){const S="The number of channels for pre-model input shape must be 1";return o(S,-1,S),0}_=b[2],v=b[3],w=b[4],I=[R,U,_,v,w]}a.Input_Shape=JSON.stringify(I),a.Output_Shape=JSON.stringify(x.output.shape),a.Channel_Last=C,a.Model_Param=await me(x),a.Model_Layers=await he(x);let Q=0;const L=D[l.preModelId-1].inferenceDelay;let M=1;const J=y.layers.length,T=[];T[0]=m.reshape(I),j(m);const Z=window.setInterval(async function(){try{T[M]=await y.layers[M].apply(T[M-1],f.deleteTextureThreshold)}catch(S){const H="Your graphics card (e.g. Intel) may not be compatible with WebGL. "+S.message;return o(H,-1,H),window.clearInterval(Z),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=S.message,a.Extra_Err_Info="PreModel Failed while model layer "+M+" apply",o("",-1,"",a),0}if(y.layers[M].dispose(),T[M-1].dispose(),o("Layer "+M.toString(),(M+1)/J),X().unreliable){const S="unreliable reasons :"+X().reasons;o(S,NaN,S)}if(M===J-1){window.clearInterval(Z);const S=C?-1:1;console.log(" find argmax "),console.log("last Tensor shape : ",T[M].shape);const H=C?T[M].shape[4]:T[M].shape[1];let k;try{console.log(" Try tf.argMax for fullVolume .."),k=await Pe(T[M],S)}catch(z){if(S===-1)try{const W=performance.now();console.log(" tf.argMax failed .. try argMaxLarge .."),window.alert("tensor2LightBuffer() is not dead code?"),window.alert("argMaxLarge() is not dead code?"),console.log("argMaxLarge for fullVolume takes : ",((performance.now()-W)/1e3).toFixed(4))}catch(W){const V="argMax buffer couldn't be created due to limited memory resources.";return o(V,-1,V),k.dispose(),window.clearInterval(Z),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=W.message,a.Extra_Err_Info="preModel prediction_argmax from argMaxLarge failed",o("",-1,"",a),0}else{const W="argMax buffer couldn't be created due to limited memory resources.";return o(W,-1,W),k.dispose(),window.clearInterval(Z),O().endScope(),O().disposeVariables(),a.Inference_t=1/0,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=z.message,a.Extra_Err_Info="preModel prediction_argmax from argMaxLarge not support yet channel first",o("",-1,"",a),0}}console.log(" Pre-model prediction_argmax shape : ",k.shape);const $=((performance.now()-g)/1e3).toFixed(4);j(T[M]),console.log(" Pre-model find array max ");const K=await k.max().dataSync()[0];Q<K&&(Q=K);const B=Q+1;console.log("Pre-model numSegClasses",B),a.Actual_Labels=B,a.Expect_Labels=H,a.NumLabels_Match=B===H;let E=await k.reshape([n,u,t]);j(k),p&&(console.log("Pre-model outLabelVolume transposed"),E=E.transpose());const q=performance.now();console.log("Generating pre-model output");let F;try{const z=await de(E);F=await Ye(z,n,u,t,l,f,o,d,!1),await j(E),console.log(" Phase-1 num of tensors after generateBrainMask: ",X().numTensors)}catch(z){O().endScope(),O().disposeVariables();const W="Failed while generating pre-model output due to limited browser memory available";return o(W,-1,W),a.Inference_t=$,a.Postprocess_t=1/0,a.Status="Fail",a.Error_Type=z.message,a.Extra_Err_Info="Pre-model failed while generating output",o("",-1,"",a),0}const N=((performance.now()-q)/1e3).toFixed(4);if(console.log("Pre-model processing the whole brain volume in tfjs tooks for multi-class output mask : ",((performance.now()-g)/1e3).toFixed(4)+"  Seconds"),a.Inference_t=$,a.Postprocess_t=N,a.Status="OK",o("",-1,"",a),F==null){const z="slice_3d_mask failed ...";return o(z,-1,z),0}else if(console.log("--- pre-model done ---"),i){if(l.enableSeqConv)return console.log("------ Mask Cropping & Seq Convoluton ------"),await Be(f,l,r,e,n,u,t,F,o,d,a,s),0;console.log("------ Mask Cropping  -  NO Seq Convoluton ------"),await Ne(r,e,n,u,t,F,l,a,f,d,o,s)}else window.alert("inferenceSubVolumes() is not dead code?")}M++},L)}catch(g){o(g.message,-1,g.message),console.log('If webgl context is lost, try to restore webgl context by visit the link <a href="https://support.biodigital.com/hc/en-us/articles/218322977-How-to-turn-on-WebGL-in-my-browser">here</a>')}}else console.log("--- No pre-model is selected ---"),console.log("------ Run voxel cropping ------"),i?l.enableSeqConv?(console.log("------ Seq Convoluton ------"),await Be(f,l,r,e,n,u,t,null,o,d,a,s)):Ne(r,e,n,u,t,null,l,a,f,d,o,s):window.alert("inferenceSubVolumes() is not dead code?")}async function ao(r=!0,e=0){await Qe(),oe().set("DEBUG",!1),oe().set("WEBGL_FORCE_F16_TEXTURES",r),oe().set("WEBGL_DELETE_TEXTURE_THRESHOLD",e),await He(),console.log("tf env() flags :",oe().flags),console.log("tf env() features :",oe().features),console.log("tf env total features: ",Object.keys(oe().features).length),console.log(ve())}async function ro(r,e,n,u,t,i){const l=[];l.startTime=Date.now(),i("Segmentation started",0),performance.now();const a=r.batchSize,f=r.numOfChan;if(isNaN(a)||a!==1){const _="The batch Size for input shape must be 1";return i(_,-1,_),0}if(isNaN(f)||f!==1){const _="The number of channels for input shape must be 1";return i(_,-1,_),0}O().startScope(),console.log("Batch size: ",a),console.log("Num of Channels: ",f);const d=await Ee(r.rootURL+e.path);await ao(!0,r.deleteTextureThreshold),l.TF_Backend=ve();const o=d;let s=[];if(s=o.layers[0].batchInputShape,console.log(" Model batch input shape : ",s),s.length!==5){const _="The model input shape must be 5D";return i(_,-1,_),0}let h,p,c;const m=n.dims[1],y=n.dims[2],g=n.dims[3];if(await re(o)){if(console.log("Model Channel Last"),isNaN(s[4])||s[4]!==1){const _="The number of channels for input shape must be 1";return i(_,-1,_),0}h=s[1],p=s[2],c=s[3]}else{if(console.log("Model Channel First"),isNaN(s[1])||s[1]!==1){const _="The number of channels for input shape must be 1";return i(_,-1,_),0}h=s[2],p=s[3],c=s[4]}let b;h===256&&p===256&&c===256?b=!0:b=!1,l.isModelFullVol=b;let C=await De(g,n,u);const R=e.enableTranspose,U=e.enableCrop;b&&(U?await no(d,C,g,y,m,b,e,l,r,t,i,u):(console.log("Cropping Disabled"),R?(C=C.transpose(),console.log("Input transposed")):console.log("Transpose NOT Enabled"),e.enableSeqConv?(console.log("Seq Convoluton Enabled"),window.alert("inferenceFullVolumeSeqCovLayer() is not dead code?")):(console.log("Seq Convoluton Disabled"),window.alert("inferenceFullVolume() is not dead code?"))))}async function we(){return navigator.userAgent.indexOf("OPR/")>-1?"Opera":navigator.userAgent.indexOf("Edg/")>-1?"Edge":navigator.userAgent.indexOf("Falkon/")>-1?"Falkon":navigator.userAgent.indexOf("Chrome/")>-1?"Chrome":navigator.userAgent.indexOf("Firefox/")>-1?"Firefox":navigator.userAgent.indexOf("Safari/")>-1?"Safari":navigator.userAgent.indexOf("MSIE/")>-1||navigator.userAgent.indexOf("rv:")>-1?"IExplorer":"Unknown"}async function so(){return navigator.userAgent.indexOf("OPR/")>-1?parseInt(navigator.userAgent.split("OPR/")[1]):navigator.userAgent.indexOf("Edg/")>-1?parseInt(navigator.userAgent.split("Edg/")[1]):navigator.userAgent.indexOf("Falkon/")>-1?parseInt(navigator.userAgent.split("Falkon/")[1]):navigator.userAgent.indexOf("Chrome/")>-1?parseInt(navigator.userAgent.split("Chrome/")[1]):navigator.userAgent.indexOf("Firefox/")>-1?parseInt(navigator.userAgent.split("Firefox/")[1]):navigator.userAgent.indexOf("Safari/")>-1?parseInt(navigator.userAgent.split("Safari/")[1]):navigator.userAgent.indexOf("MSIE/")>-1||navigator.userAgent.indexOf("rv:")>-1?parseInt(navigator.userAgent.split("MSIE/")[1]):1/0}async function to(){return navigator.userAgent.indexOf("Win")>-1?"Windows":navigator.userAgent.indexOf("Mac")>-1?"MacOS":navigator.userAgent.indexOf("Linux")>-1?"Linux":navigator.userAgent.indexOf("UNIX")>-1?"UNIX":"Unknown"}async function lo(r){return r?(console.log("WebGl2 is enabled"),!0):(console.log(typeof WebGL2RenderingContext!="undefined"?"WebGL2 may be disabled. Please try updating video card drivers":"WebGL2 is not supported"),!1)}async function io(r){let e;if(r&&(e=r.getExtension("WEBGL_debug_renderer_info"),e)){const n=r.getParameter(e.UNMASKED_VENDOR_WEBGL);return n.indexOf("(")>-1&&n.indexOf(")")>-1?n.substring(n.indexOf("(")+1,n.indexOf(")")):n}return null}async function co(r){if(r){const e=r.getExtension("WEBGL_debug_renderer_info");return e?r.getParameter(e.UNMASKED_VENDOR_WEBGL):null}else return null}async function uo(r){if(r){if(we()==="Firefox")return r.getParameter(r.RENDERER);const e=r.getExtension("WEBGL_debug_renderer_info");return e?r.getParameter(e.UNMASKED_RENDERER_WEBGL):null}else return null}async function po(r){let e;if(r){if(we()==="Firefox")return r.getParameter(r.RENDERER);if(e=r.getExtension("WEBGL_debug_renderer_info"),e){let n=r.getParameter(e.UNMASKED_RENDERER_WEBGL);return n.indexOf("(")>-1&&n.indexOf(")")>-1&&n.indexOf("(R)")===-1&&(n=n.substring(n.indexOf("(")+1,n.indexOf(")")),n.split(",").length===3)?n.split(",")[1].trim():n}}return null}async function fo(){return navigator.hardwareConcurrency}async function Fe(){return/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)}async function ho(r,e=null){const n=new Date;if(r.isModelFullVol?r.Brainchop_Ver="FullVolume":r.Brainchop_Ver="SubVolumes",r.Total_t=(Date.now()-r.startTime)/1e3,delete r.startTime,r.Date=parseInt(n.getMonth()+1)+"/"+n.getDate()+"/"+n.getFullYear(),r.Browser=await we(),r.Browser_Ver=await so(),r.OS=await to(),r.WebGL2=await lo(e),r.GPU_Vendor=await io(e),r.GPU_Card=await po(e),r.GPU_Vendor_Full=await co(e),r.GPU_Card_Full=await uo(e),r.CPU_Cores=await fo(),r.Which_Brainchop="latest",await Fe()&&(r.Heap_Size_MB=window.performance.memory.totalJSHeapSize/(1024*1024).toFixed(2),r.Used_Heap_MB=window.performance.memory.usedJSHeapSize/(1024*1024).toFixed(2),r.Heap_Limit_MB=window.performance.memory.jsHeapSizeLimit/(1024*1024).toFixed(2)),e){console.log("MAX_TEXTURE_SIZE :",e.getParameter(e.MAX_TEXTURE_SIZE)),console.log("MAX_RENDERBUFFER_SIZE :",e.getParameter(e.MAX_RENDERBUFFER_SIZE));const u=e.getExtension("WEBGL_debug_renderer_info");console.log("VENDOR WEBGL:",e.getParameter(u.UNMASKED_VENDOR_WEBGL)),r.Texture_Size=e.getParameter(e.MAX_TEXTURE_SIZE)}else r.Texture_Size=null;return r}function mo(){return new Worker("/assets/brainchop-webworker.700f1548.js",{type:"module"})}async function go(){dragMode.onchange=async function(){s.opts.dragMode=this.selectedIndex},drawDrop.onchange=async function(){if(s.volumes.length<2){window.alert("No segmentation open (use the Segmentation pull down)"),drawDrop.selectedIndex=-1;return}if(!s.drawBitmap){window.alert("No drawing (hint: use the Draw pull down to select a pen)"),drawDrop.selectedIndex=-1;return}const c=parseInt(this.value);if(c===0){s.drawUndo(),drawDrop.selectedIndex=-1;return}let m=s.volumes[1].img,y=await s.saveImage({filename:"",isSaveDrawing:!0});const g=352,x=y.length;if(c===1)for(let b=0;b<x;b++)y[g+b]>0&&(m[b]=1);if(c===2)for(let b=0;b<x;b++)y[g+b]>0&&(m[b]=0);s.closeDrawing(),s.updateGLVolume(),s.setDrawingEnabled(!1),penDrop.selectedIndex=-1,drawDrop.selectedIndex=-1},penDrop.onchange=async function(){const c=parseInt(this.value);s.setDrawingEnabled(c>=0),c>=0&&s.setPenValue(c&7,c>7)},aboutBtn.onclick=function(){window.alert("Drag and drop NIfTI images. Use pulldown menu to choose brainchop model")},diagnosticsBtn.onclick=function(){if(d.length<1){window.alert("No diagnostic string generated: run a model to create diagnostics");return}navigator.clipboard.writeText(d),window.alert(`Diagnostics copied to clipboard
`+d)},opacitySlider0.oninput=function(){s.setOpacity(0,opacitySlider0.value/255),s.updateGLVolume()},opacitySlider1.oninput=function(){s.setOpacity(1,opacitySlider1.value/255)};async function r(){const c=s.volumes[0];let m=c.dims[1]===256&&c.dims[2]===256&&c.dims[3]===256;if((c.permRAS[0]!==-1||c.permRAS[1]!==3||c.permRAS[2]!==-2)&&(m=!1),m)return;const y=await s.conform(c,!1);await s.removeVolume(s.volumes[0]),await s.addVolume(y)}async function e(){for(;s.volumes.length>1;)await s.removeVolume(s.volumes[1])}modelSelect.onchange=async function(){this.selectedIndex<0&&(modelSelect.selectedIndex=11),await e(),await r();const c=D[this.selectedIndex],m=Ze;m.deleteTextureThreshold=deleteTextureCheck.checked?0:-1;const y=new URL(window.location.href);if(m.rootURL=y.origin+y.pathname,Boolean(window.location.hostname==="localhost"||window.location.hostname==="[::1]"||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/))&&(m.rootURL=location.protocol+"//"+location.host),workerCheck.checked){if(typeof o!="undefined"){console.log("Unable to start new segmentation: previous call has not completed");return}o=await new mo;const x={datatypeCode:s.volumes[0].hdr.datatypeCode,dims:s.volumes[0].hdr.dims},b={opts:m,modelEntry:c,niftiHeader:x,niftiImage:s.volumes[0].img};o.postMessage(b),o.onmessage=function(C){const R=C.data.cmd;R==="ui"&&(C.data.modalMessage!==""&&(o.terminate(),o=void 0),l(C.data.message,C.data.progressFrac,C.data.modalMessage,C.data.statData)),R==="img"&&(o.terminate(),o=void 0,t(C.data.img,C.data.opts,C.data.modelEntry))}}else ro(m,c,s.volumes[0].hdr,s.volumes[0].img,t,l)},saveImgBtn.onclick=function(){s.volumes[1].saveToDisk("Custom.nii")},saveSceneBtn.onclick=function(){s.saveDocument("brainchop.nvd")},workerCheck.onchange=function(){modelSelect.onchange()},deleteTextureCheck.onchange=function(){modelSelect.onchange()},clipCheck.onchange=function(){clipCheck.checked?s.setClipPlane([0,0,90]):s.setClipPlane([2,0,90])};function n(){opacitySlider0.oninput()}async function u(c){return await(await fetch(c)).json()}async function t(c,m,y){e();const g=await s.volumes[0].clone();if(g.zeroImage(),g.hdr.scl_inter=0,g.hdr.scl_slope=1,g.img=new Uint8Array(c),y.colormapPath){const x=await u(y.colormapPath);g.setColormapLabel(x),g.hdr.intent_code=1002}else{let x=m.atlasSelectedColorTable.toLowerCase();s.colormaps().includes(x)||(x="actc"),g.colormap=x}g.opacity=opacitySlider1.value/255,await s.addVolume(g)}async function i(c){(typeof c=="string"||c instanceof String)&&(c=function(y){const g=JSON.parse(y),x=[];for(const b in g)x[b]=g[b];return x}(c)),c=await ho(c,s.gl),d=`:: Diagnostics can help resolve issues https://github.com/neuroneural/brainchop/issues ::
`;for(const m in c)d+=m+": "+c[m]+`
`}function l(c="",m=-1,y="",g=[]){c!==""&&(console.log(c),document.getElementById("location").innerHTML=c),isNaN(m)?(memstatus.style.color="red",memstatus.innerHTML="Memory Issue"):m>=0&&(modelProgress.value=m*modelProgress.max),y!==""&&window.alert(y),Object.keys(g).length>0&&i(g)}function a(c){document.getElementById("location").innerHTML="&nbsp;&nbsp;"+c.string}const f={backColor:[.4,.4,.4,1],show3Dcrosshair:!0,onLocationChange:a};let d="",o;const s=new Xe(f);s.attachToCanvas(gl1),s.opts.dragMode=s.dragModes.pan,s.opts.multiplanarForceRender=!0,s.opts.yoke3Dto2DZoom=!0,s.opts.crosshairGap=11,s.setInterpolation(!0),await s.loadVolumes([{url:"./t1_crop.nii.gz"}]);for(let c=0;c<D.length;c++){const m=document.createElement("option");m.text=D[c].modelName,m.value=D[c].id.toString(),modelSelect.appendChild(m)}s.onImageLoaded=n,modelSelect.selectedIndex=-1,drawDrop.selectedIndex=-1,workerCheck.checked=await Fe();const p=new URLSearchParams(window.location.search).get("model");p&&(modelSelect.selectedIndex=Number(p),modelSelect.onchange())}go();
